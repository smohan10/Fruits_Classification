{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + \"\\\\data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(data_path, folder_type='train'):\n",
    "    if folder_type.lower() == 'train':\n",
    "        path = data_path + \"\\\\\" + \"Training\"\n",
    "    elif folder_type.lower() == 'test':\n",
    "        path = data_path + \"\\\\\" + \"Test\"\n",
    "    else:\n",
    "        print(\"Wrong folder path\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    total_fruits_list  = os.listdir(path)\n",
    "    total_fruits_count = len(total_fruits_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_images_count = 0\n",
    "    \n",
    "    total_fruits_list_temp = total_fruits_list[:5]\n",
    "    total_fruits_count_temp = len(total_fruits_list_temp)\n",
    "    \n",
    "    for fruit in total_fruits_list_temp:        \n",
    "        for img in os.listdir(path + \"\\\\\" + fruit):\n",
    "            all_images_count += 1\n",
    "            \n",
    "    \n",
    "    data = {}\n",
    "    labels = {}\n",
    "    data[folder_type] = np.zeros(shape=(all_images_count, 100, 100, 3), dtype=np.float32)\n",
    "    labels[folder_type] = np.zeros(all_images_count, dtype=np.int32)\n",
    "    print(data[folder_type].shape)\n",
    "    print(labels[folder_type].shape)\n",
    "    \n",
    "    data_counter = 0\n",
    "    label_counter = 0\n",
    "    \n",
    "    label_to_idx_dict = {}\n",
    "    idx_to_label_dict = {}\n",
    "    \n",
    "    for fruit in total_fruits_list_temp:        \n",
    "        print(folder_type, \" : \", fruit)  \n",
    "        label_to_idx_dict[fruit] = label_counter\n",
    "        idx_to_label_dict[label_counter] = fruit\n",
    "        for img in os.listdir(path + \"\\\\\" + fruit):\n",
    "            cur_img = cv2.imread(path + \"\\\\\" + fruit + \"\\\\\" + img)            \n",
    "            data[folder_type][data_counter,:,:,:] = cur_img                        \n",
    "            labels[folder_type][data_counter] = label_counter\n",
    "            data_counter += 1\n",
    "        label_counter += 1\n",
    "            \n",
    "    return data[folder_type], labels[folder_type], len(total_fruits_list_temp), label_to_idx_dict, idx_to_label_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2449, 100, 100, 3)\n",
      "(2449,)\n",
      "train  :  Apple Braeburn\n",
      "train  :  Apple Golden 1\n",
      "train  :  Apple Golden 2\n",
      "train  :  Apple Golden 3\n",
      "train  :  Apple Granny Smith\n",
      "(817, 100, 100, 3)\n",
      "(817,)\n",
      "test  :  Apple Braeburn\n",
      "test  :  Apple Golden 1\n",
      "test  :  Apple Golden 2\n",
      "test  :  Apple Golden 3\n",
      "test  :  Apple Granny Smith\n"
     ]
    }
   ],
   "source": [
    "training_data, training_labels, num_classes, \\\n",
    "    label_to_idx_dict_train,idx_to_label_dict_train = read(data_path, folder_type=\"train\")\n",
    "\n",
    "test_data, test_labels, num_classes, \\\n",
    "    label_to_idx_dict_test, idx_to_label_dict_test = read(data_path, folder_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhf_train_data = h5py.File(\\'training_data.h5\\', \\'w\\')\\nhf_train_labels = h5py.File(\\'training_labels.h5\\', \\'w\\')\\nhf_test_data = h5py.File(\\'test_data.h5\\', \\'w\\')\\nhf_test_labels = h5py.File(\\'test_labels.h5\\', \\'w\\')\\n\\nhf_train_data.create_dataset(\\'training_data\\', data=training_data)\\nasciiList = [n.encode(\"ascii\", \"ignore\") for n in training_labels]\\nhf_train_labels.create_dataset(\\'training_labels\\', (len(asciiList),1),\\'S25\\', asciiList)\\n\\nhf_test_data.create_dataset(\\'test_data\\', data=test_data)\\nasciiList_test = [n.encode(\"ascii\", \"ignore\") for n in test_labels]\\nhf_test_labels.create_dataset(\\'test_labels\\', (len(asciiList_test),1),\\'S25\\', asciiList_test)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hf_train_data = h5py.File('training_data.h5', 'w')\n",
    "hf_train_labels = h5py.File('training_labels.h5', 'w')\n",
    "hf_test_data = h5py.File('test_data.h5', 'w')\n",
    "hf_test_labels = h5py.File('test_labels.h5', 'w')\n",
    "\n",
    "hf_train_data.create_dataset('training_data', data=training_data)\n",
    "asciiList = [n.encode(\"ascii\", \"ignore\") for n in training_labels]\n",
    "hf_train_labels.create_dataset('training_labels', (len(asciiList),1),'S25', asciiList)\n",
    "\n",
    "hf_test_data.create_dataset('test_data', data=test_data)\n",
    "asciiList_test = [n.encode(\"ascii\", \"ignore\") for n in test_labels]\n",
    "hf_test_labels.create_dataset('test_labels', (len(asciiList_test),1),'S25', asciiList_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data is (2449, 100, 100, 3)\n",
      "Shape of training labels is (2449,)\n",
      "Shape of test data is (817, 100, 100, 3)\n",
      "Shape of test labels is (817,)\n"
     ]
    }
   ],
   "source": [
    "# Display the dimensions of the data\n",
    "print(\"Shape of training data is {}\".format(training_data.shape)) \n",
    "print(\"Shape of training labels is {}\".format(training_labels.shape)) \n",
    "\n",
    "print(\"Shape of test data is {}\".format(test_data.shape)) \n",
    "print(\"Shape of test labels is {}\".format(test_labels.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Apple Braeburn': 0,\n",
       "  'Apple Golden 1': 1,\n",
       "  'Apple Golden 2': 2,\n",
       "  'Apple Golden 3': 3,\n",
       "  'Apple Granny Smith': 4},\n",
       " 5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_idx_dict_train, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent labels as one hot encoding\n",
    "#training_labels_one_hot = tf.one_hot(training_labels, num_classes)\n",
    "#test_labels_one_hot = tf.one_hot(test_labels, num_classes)\n",
    "#with tf.Session() as sess:\n",
    "#    print(sess.run(training_labels_one_hot))\n",
    "#    print(sess.run(test_labels_one_hot))\n",
    "    \n",
    "training_labels_one_hot = np.eye(num_classes)[training_labels.reshape(-1)]\n",
    "test_labels_one_hot = np.eye(num_classes)[test_labels.reshape(-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2449, 5)\n"
     ]
    }
   ],
   "source": [
    "print(training_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized training data is (2449, 100, 100, 3)\n",
      "Shape of normalized test data is (817, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the input\n",
    "training_data_norm = training_data/255.0\n",
    "test_data_norm = test_data/255.0\n",
    "\n",
    "print(\"Shape of normalized training data is {}\".format(training_data_norm.shape)) \n",
    "print(\"Shape of normalized test data is {}\".format(test_data_norm.shape)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the architecture \n",
    "\n",
    "1. Conv2D - 16 5 x 5 x 3 filters\n",
    "2. Batch Norm\n",
    "3. Relu\n",
    "4. Max Pool - 2x2 Stride 2\n",
    "\n",
    "1. Conv2D - 32 5x5x16 filters\n",
    "2. Batch Norm\n",
    "3. Relu\n",
    "4. Max Pool - 2x2 Stride 2\n",
    "\n",
    "1. Conv2D - 64 5x5x32 filters\n",
    "2. Batch Norm\n",
    "3. Relu\n",
    "4. Max Pool - 2x2 Stride 2\n",
    "\n",
    "1. Conv2D - 128 5x5x64 filters\n",
    "2. Batch Norm\n",
    "3. Relu\n",
    "4. Max Pool - 2x2 Stride 2\n",
    "\n",
    "1. Fully Connected - 1024\n",
    "2. Fully Connected - 256 \n",
    "\n",
    "1. Softmax  - 81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    parameters = {}\n",
    "    \n",
    "    parameters[\"W1\"] = tf.get_variable(\"W1\", shape=(5,5,3,16), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters[\"W2\"] = tf.get_variable(\"W2\", shape=(5,5,16,32), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters[\"W3\"] = tf.get_variable(\"W3\", shape=(5,5,32,64), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters[\"W4\"] = tf.get_variable(\"W4\", shape=(5,5,64,128), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    \n",
    "    return parameters\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 1 convolution block \n",
    "def conv2d_Block(X, W, s, padding='SAME'):\n",
    "    \n",
    "    Z = tf.nn.conv2d(X, W, strides=[1,s,s,1], padding=padding)\n",
    "    \n",
    "    A = tf.nn.relu(Z)\n",
    "    \n",
    "    return A\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max pool block\n",
    "def maxpool2d_Block(X, f, padding='SAME'):\n",
    "\n",
    "    max_pool = tf.nn.max_pool(X, [1,f,f,1], strides=[1,f,f,1], padding=padding)\n",
    "    \n",
    "    return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward activation\n",
    "\n",
    "def forward_pass(X, parameters):\n",
    "    \n",
    "    \n",
    "    # Perform series of convolution operation\n",
    "    C1 = conv2d_Block(X, parameters[\"W1\"], 1, \"SAME\")\n",
    "    M1 = maxpool2d_Block(C1, 2, \"SAME\")\n",
    "    \n",
    "    C2 = conv2d_Block(M1,  parameters[\"W2\"], 1, \"SAME\")\n",
    "    M2 = maxpool2d_Block(C2, 2,  \"SAME\")\n",
    "    \n",
    "    C3 = conv2d_Block(M2,  parameters[\"W3\"], 1, \"SAME\")\n",
    "    M3 = maxpool2d_Block(C3, 2,  \"SAME\")\n",
    "    \n",
    "    C4 = conv2d_Block(M3, parameters[\"W4\"], 1, \"SAME\")\n",
    "    M4 = maxpool2d_Block(C4, 2, \"SAME\")\n",
    "    \n",
    "    # Flatten \n",
    "    P4 =  tf.contrib.layers.flatten(M4)\n",
    "    \n",
    "    # Fully connected - 1\n",
    "    F1 = tf.contrib.layers.fully_connected(P4, 1024)\n",
    "    \n",
    "    # Fully connected - 2\n",
    "    F2 = tf.contrib.layers.fully_connected(F1, 256)\n",
    "    \n",
    "    # last layer\n",
    "    F3 = tf.contrib.layers.fully_connected(F2, 5, activation_fn=None)\n",
    "    \n",
    "    return F3\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cost\n",
    "\n",
    "def compute_cost(logits, labels):\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "def optimizer(alpha, cost):\n",
    "    \n",
    "    train = tf.train.AdamOptimizer(alpha).minimize(cost)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "def model(X_train, y_train, X_test, y_test,num_epochs=1000, mini_batch_size=64, learning_rate=0.001):\n",
    "    \n",
    "     # to be able to rerun the model without overwriting tf variables\n",
    "    ops.reset_default_graph()                        \n",
    "    \n",
    "    # Extract information from the data\n",
    "    m, nH, nW, nC = X_train.shape\n",
    "    num_classes = y_train.shape[-1]\n",
    "    overall_cost = []\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters() \n",
    "    \n",
    "    # Create placeholders for X and y\n",
    "    X_ = tf.placeholder(shape=[None, nH, nW, nC], dtype=tf.float32)\n",
    "    y_ = tf.placeholder(shape=[None, num_classes], dtype=tf.float32)\n",
    "    \n",
    "    # Call the forward pass\n",
    "    Z = forward_pass(X_, parameters)\n",
    "    \n",
    "    # Compute the cost\n",
    "    cost = compute_cost(Z, y_)\n",
    "    \n",
    "    # Define an optimizer for training\n",
    "    train = optimizer(learning_rate, cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    \n",
    "            \n",
    "    # Create a tensorflow session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        batches = int(np.floor(m/mini_batch_size))\n",
    "        print(\"Total number of batches: %d \" % batches)\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            \n",
    "            batch_counter = 0 \n",
    "            mini_batches_input_list = []\n",
    "            random_idx = np.random.permutation(m)\n",
    "            \n",
    "            for k in range(batches):\n",
    "                mini_batches_input_list.append( (X_train[mini_batch_size*k : mini_batch_size*(k+1)], \n",
    "                                               y_train[mini_batch_size*k : mini_batch_size*(k+1)]))\n",
    "                \n",
    "            mini_batches_input_list.append((X_train[batches*mini_batch_size : ], \n",
    "                                               y_train[batches*mini_batch_size : ]))\n",
    "            \n",
    "            for mini_batch in mini_batches_input_list:\n",
    "                \n",
    "                mini_batch_X, mini_batch_y = mini_batch[0], mini_batch[1]\n",
    "                \n",
    "                \n",
    "                _, cur_cost = sess.run(train, feed_dict = {X_:mini_batch_X, y_:mini_batch_y}), \\\n",
    "                                sess.run(cost, feed_dict = {X_:mini_batch_X, y_:mini_batch_y})\n",
    "                \n",
    "                overall_cost.append(cur_cost)\n",
    "                #print(\"Current cost: %f\" % cur_cost)\n",
    "                \n",
    "                batch_counter += 1\n",
    "                if batch_counter == 2:\n",
    "                    break\n",
    "                    \n",
    "            if i % 10 == 0:\n",
    "                print(\"Cost at iteration %d is %f\" % (i, overall_cost[-1]))\n",
    "                print(\"Saving a checkpoint here.\")\n",
    "                saver.save(sess, os.getcwd() + \"\\\\fruit_train\", global_step=i)\n",
    "                \n",
    "        print(\"Training done\")\n",
    "        '''correct_pred = tf.equal(tf.argmax(Z, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "\n",
    "        train_accuracy = accuracy.eval({X_: X_test, y_: y_test})\n",
    "        print(\"Accuracy: \", train_accuracy)'''\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    return overall_cost, parameters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches: 38 \n",
      "Cost at iteration 0 is 0.000000\n",
      "Saving a checkpoint here.\n",
      "Cost at iteration 10 is 0.000000\n",
      "Saving a checkpoint here.\n",
      "Cost at iteration 20 is 0.000000\n",
      "Saving a checkpoint here.\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "overall_cost, parameters = model(training_data_norm, training_labels_one_hot, \n",
    "                                           test_data_norm, test_labels_one_hot, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0005023889, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(overall_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2690e59f4a8>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(overall_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = tf.placeholder(shape=[None, 100, 100, 3], dtype=tf.float32)\n",
    "y_ = tf.placeholder(shape=[None, 5], dtype=tf.float32)\n",
    "    \n",
    "Z = forward_pass(X_, parameters)\n",
    "correct_pred = tf.equal(tf.argmax(Z, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "#test_accuracy = sess.run(accuracy, {X_: test_data_norm, y_: test_labels_one_hot})\n",
    "argZ = sess.run(tf.argmax(Z, 1), {X_: test_data_norm, y_: test_labels_one_hot})\n",
    "argA = sess.run(tf.argmax(tf.nn.softmax(Z), 1), {X_: test_data_norm, y_: test_labels_one_hot})\n",
    "argY = sess.run(tf.argmax(y_, 1), {X_: test_data_norm, y_: test_labels_one_hot})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
