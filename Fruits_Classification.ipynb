{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Softwares\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + \"\\\\data\\\\fruits-360\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(data_path, folder_type='train'):\n",
    "    if folder_type.lower() == 'train':\n",
    "        path = data_path + \"\\\\\" + \"Training\"\n",
    "    elif folder_type.lower() == 'test':\n",
    "        path = data_path + \"\\\\\" + \"Test\"\n",
    "    else:\n",
    "        print(\"Wrong folder path\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    total_fruits_list  = os.listdir(path)\n",
    "    total_fruits_count = len(total_fruits_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_images_count = 0\n",
    "    \n",
    "    total_fruits_list_temp = total_fruits_list[:5]\n",
    "    total_fruits_count_temp = len(total_fruits_list_temp)\n",
    "    \n",
    "    for fruit in total_fruits_list_temp:        \n",
    "        for img in os.listdir(path + \"\\\\\" + fruit):\n",
    "            all_images_count += 1\n",
    "            \n",
    "    \n",
    "    data = {}\n",
    "    labels = {}\n",
    "    data[folder_type] = np.zeros(shape=(all_images_count, 100, 100, 3), dtype=np.float64)\n",
    "    labels[folder_type] = np.zeros(all_images_count)\n",
    "    print(data[folder_type].shape)\n",
    "    print(labels[folder_type].shape)\n",
    "    \n",
    "    data_counter = 0\n",
    "    label_counter = 0\n",
    "    \n",
    "    label_to_idx_dict = {}\n",
    "    idx_to_label_dict = {}\n",
    "    \n",
    "    for fruit in total_fruits_list_temp:        \n",
    "        print(folder_type, \" : \", fruit)  \n",
    "        label_to_idx_dict[fruit] = label_counter\n",
    "        idx_to_label_dict[label_counter] = fruit\n",
    "        for img in os.listdir(path + \"\\\\\" + fruit):\n",
    "            cur_img = cv2.imread(path + \"\\\\\" + fruit + \"\\\\\" + img)            \n",
    "            data[folder_type][data_counter,:,:,:] = cur_img                        \n",
    "            labels[folder_type][data_counter] = label_counter\n",
    "            data_counter += 1\n",
    "        label_counter += 1\n",
    "            \n",
    "    return data[folder_type], labels[folder_type], len(total_fruits_list_temp), label_to_idx_dict, idx_to_label_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2449, 100, 100, 3)\n",
      "(2449,)\n",
      "train  :  Apple Braeburn\n",
      "train  :  Apple Golden 1\n",
      "train  :  Apple Golden 2\n",
      "train  :  Apple Golden 3\n",
      "train  :  Apple Granny Smith\n",
      "(817, 100, 100, 3)\n",
      "(817,)\n",
      "test  :  Apple Braeburn\n",
      "test  :  Apple Golden 1\n",
      "test  :  Apple Golden 2\n",
      "test  :  Apple Golden 3\n",
      "test  :  Apple Granny Smith\n"
     ]
    }
   ],
   "source": [
    "training_data, training_labels, num_classes, \\\n",
    "    label_to_idx_dict_train,idx_to_label_dict_train = read(data_path, folder_type=\"train\")\n",
    "\n",
    "test_data, test_labels, num_classes, \\\n",
    "    label_to_idx_dict_test, idx_to_label_dict_test = read(data_path, folder_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "hf_train_data = h5py.File('training_data.h5', 'w')\n",
    "hf_train_labels = h5py.File('training_labels.h5', 'w')\n",
    "hf_test_data = h5py.File('test_data.h5', 'w')\n",
    "hf_test_labels = h5py.File('test_labels.h5', 'w')\n",
    "\n",
    "hf_train_data.create_dataset('training_data', data=training_data)\n",
    "asciiList = [n.encode(\"ascii\", \"ignore\") for n in training_labels]\n",
    "hf_train_labels.create_dataset('training_labels', (len(asciiList),1),'S25', asciiList)\n",
    "\n",
    "hf_test_data.create_dataset('test_data', data=test_data)\n",
    "asciiList_test = [n.encode(\"ascii\", \"ignore\") for n in test_labels]\n",
    "hf_test_labels.create_dataset('test_labels', (len(asciiList_test),1),'S25', asciiList_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data is (2449, 100, 100, 3)\n",
      "Shape of training labels is (2449,)\n",
      "Shape of test data is (817, 100, 100, 3)\n",
      "Shape of test labels is (817,)\n"
     ]
    }
   ],
   "source": [
    "# Display the dimensions of the data\n",
    "print(\"Shape of training data is {}\".format(training_data.shape)) \n",
    "print(\"Shape of training labels is {}\".format(training_labels.shape)) \n",
    "\n",
    "print(\"Shape of test data is {}\".format(test_data.shape)) \n",
    "print(\"Shape of test labels is {}\".format(test_labels.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple Braeburn': 0,\n",
       " 'Apple Golden 1': 1,\n",
       " 'Apple Golden 2': 2,\n",
       " 'Apple Golden 3': 3,\n",
       " 'Apple Granny Smith': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_idx_dict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent labels as one hot encoding\n",
    "training_labels_one_hot = tf.one_hot(training_labels, num_classes)\n",
    "test_labels_one_hot = tf.one_hot(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(training_labels_one_hot))\n",
    "    print(sess.run(test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized training data is (2449, 100, 100, 3)\n",
      "Shape of normalized test data is (817, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the input\n",
    "training_data_norm = training_data/255.0\n",
    "test_data_norm = test_data/255.0\n",
    "\n",
    "print(\"Shape of normalized training data is {}\".format(training_data_norm.shape)) \n",
    "print(\"Shape of normalized test data is {}\".format(test_data_norm.shape)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the architecture \n",
    "\n",
    "1. Conv2D - 16 5 x 5 x 3 filters\n",
    "2. Batch Norm\n",
    "3. Relu\n",
    "4. Max Pool - 2x2 Stride 2\n",
    "\n",
    "1. Conv2D - 32 5x5x16 filters\n",
    "2. Batch Norm\n",
    "3. Relu\n",
    "4. Max Pool - 2x2 Stride 2\n",
    "\n",
    "1. Conv2D - 64 5x5x32 filters\n",
    "2. Batch Norm\n",
    "3. Relu\n",
    "4. Max Pool - 2x2 Stride 2\n",
    "\n",
    "1. Conv2D - 128 5x5x64 filters\n",
    "2. Batch Norm\n",
    "3. Relu\n",
    "4. Max Pool - 2x2 Stride 2\n",
    "\n",
    "1. Fully Connected - 1024\n",
    "2. Fully Connected - 256 \n",
    "\n",
    "1. Softmax  - 81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    parameters = {}\n",
    "    \n",
    "    parameters[\"W1\"] = tf.get_variable(shape=(5,5,3,16), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters[\"W2\"] = tf.get_variable(shape=(5,5,16,32), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters[\"W3\"] = tf.get_variable(shape=(5,5,32,64), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters[\"W4\"] = tf.get_variable(shape=(5,5,64,128), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    \n",
    "    return parameters\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define 1 convolution block \n",
    "def conv2d_Block(X, W, s, padding='SAME'):\n",
    "    \n",
    "    Z = tf.nn.conv2d(X, W, stride=[1,s,s,1], padding=padding)\n",
    "    \n",
    "    A = tf.nn.relu(conv)\n",
    "    \n",
    "    return A\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max pool block\n",
    "def maxpool2d_Block(X, f, padding='SAME'):\n",
    "\n",
    "    max_pool = tf.nn.max_pool(X, [1,f,f,1], stride=[1,f,f,1], padding=padding)\n",
    "    \n",
    "    return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward activation\n",
    "\n",
    "def forward_pass(X, parameters):\n",
    "    \n",
    "    \n",
    "    # Perform series of convolution operation\n",
    "    C1 = conv2d_Block(X, parameters[\"W1\"], 1, \"SAME\")\n",
    "    M1 = maxpool2d_Block(C1, 2, \"SAME\")\n",
    "    \n",
    "    C2 = conv2d_Block(M1,  parameters[\"W2\"], 1, \"SAME\")\n",
    "    M2 = maxpool2d_Block(C2, 2,  \"SAME\")\n",
    "    \n",
    "    C3 = conv2d_Block(M2,  parameters[\"W3\"], 1, \"SAME\")\n",
    "    M3 = maxpool2d_Block(C3, 2,  \"SAME\")\n",
    "    \n",
    "    C4 = conv2d_Block(M3, parameters[\" W4\"], 1, \"SAME\")\n",
    "    M4 = maxpool2d_Block(C4, 2, \"SAME\")\n",
    "    \n",
    "    # Flatten \n",
    "    P4 =  tf.contrib.layers.flatten(M4)\n",
    "    \n",
    "    # Fully connected - 1\n",
    "    F1 = tf.contrib.layers.fully_connected(P4, 1024)\n",
    "    \n",
    "    # Fully connected - 2\n",
    "    F2 = tf.contrib.layers.fully_connected(F1, 256)\n",
    "    \n",
    "    # last layer\n",
    "    F3 = tf.contrib.layers.fully_connected(F2, 81, activation_fn=None)\n",
    "    \n",
    "    return F3\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cost\n",
    "\n",
    "def compute_cost(logits, labels):\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "def optimizer(alpha, cost):\n",
    "    \n",
    "    train = tf.train.AdamOptimizer(alpha).minimize(cost)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "def model(X, y, num_iterations=, mini_batch_size=, learning_rate=, ):\n",
    "    \n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    Z = forward_pass(X, parameters)\n",
    "    \n",
    "    cost = compute_cost(Z, y)\n",
    "    \n",
    "    train = optimizer(learning_rate, cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
